{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea_2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/nachotp/Tarea2-INF395/blob/master/Tarea_2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Bw-JFoWKb7t1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
        "\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2018 </h1>\n",
        "\n",
        "<H3 align='center'> Tarea 2 - Redes Neuronales Convolucionales y Recurrentes </H3>\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "**Temas**  \n",
        "* Regularización en Redes Convolucionales.\n",
        "* Diseño e implementación de redes recurrentes (RNN) usando keras.\n",
        "* Diseño y entrenamiento de autoencoders (AEs)\n",
        "* Transfer Learning, pre-entrenamiento (*fine tunning*).\n",
        " \n",
        "\n",
        "** Formalidades **  \n",
        "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
        "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
        "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
        "* Fecha de entrega y discusión: 1 y 4 de Junio.\n",
        "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea2-INF395-I-2018]\n",
        "\n",
        "<hr style=\"height:2px;border:none\"/>\n",
        "\n",
        "La tarea se divide en secciones:\n",
        "\n",
        "[1.](#primero) Entrenamiento de RNNs en una Serie de Tiempo    \n",
        "[2.](#segundo) Redes recurrentes sobre texto  \n",
        "[3.](#tercero) Autoencoders (AEs) en MNIST  \n",
        "[4.](#cuarto) Transfer Learning\n",
        "\n",
        "*Nota: Para esta actividad si es que no se cuenta con GPU se recomienda utilizar el entorno virtual de __[Colaboratory - Google](https://colab.research.google.com/)__*\n"
      ]
    },
    {
      "metadata": {
        "id": "RfvZJEwub7t2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"primero\"></a>\n",
        "## 1. Entrenamiento de RNNs en una Serie de Tiempo\n",
        "En esta sección emplearemos redes neuronales recurrentes para modelar series de tiempo, es decir una serie\n",
        "de registros (tı́picamente valores reales) regularmente indexados en el tiempo. Para ello utilizaremos un dataset\n",
        "denominado \"*Minimum Daily Temperatures*\", el cual describe la temperatura mínima diaria en un período de 10 años (1981 a 1990) en la ciudad de Melbourne, Australia. Las unidades de las 3670 observaciones fueron medidas en grados celsius. A continuación se muestra la secuencia de tiempo:\n",
        "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/11/Minimum-Daily-Temperatures.png\" width=\"60%\" />\n",
        "\n",
        "\n",
        "\n",
        "La tarea predictiva consiste en estimar la temperatura mínima diaria de algún día basado en la información de días anteriores.  \n",
        "*La fuente es acreditada a Australian Bureau of Meteorology.*\n",
        "\n",
        "> a) Escriba una función que cargue los datos, los divida en 1500 de entrenamiento y el resto (500) de pruebas. Además de esto escálelos apropiadamente para trabajar con redes recurrentes.  \n",
        "```python\n",
        "name_f = \"time_series_data.csv\"\n",
        "dataframe = pd.read_csv(name_f,sep=',',usecols=[1],engine='python',skipfooter = 3)[:2000]\n",
        "dataframe[:] = dataframe[:].astype('float32')\n",
        "df_train, df_test = dataframe[:1500].values, dataframe[1500:].values\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1)).fit(df_train)\n",
        "stream_train_scaled = scaler.transform(df_train)\n",
        "stream_test_scaled = scaler.transform(df_test)\n",
        "```\n",
        "\n",
        "> b) Ahora nos gustarı́a manipular los datos, para que hagamos la predicción de la temperatura mínima para el tiempo siguiente usando la temperatura mínima de los últimos perı́odos de tiempo. El número de perı́odos de tiempos que usaremos se denomina *lag*. Por ejemplo, tendremos un *lag* igual a 3, si para predecir el valor $x_{t+1}$ en el tiempo siguiente usamos la información del tiempo actual $x_t$ y la de los dos perı́odos anteriores $x_{t-1}$ y $x_{t-2}$ como variables de entrada. Realice una función que reciba una secuencia de valores y la transforme en dos arreglos *dataX* (inputs) y *dataY* (targets) donde el número de caracterı́sticas de la la matriz de entrada (columnas) sea el número de tiempos que se considerarán como información (*lag*).\n",
        "```python\n",
        "def create_dataset(dataset,lag=1):\n",
        "    return np.array(dataX),np.array(dataY)\n",
        "```\n",
        "Por ejemplo si en el dataset tenemos el arreglo 20.7,17.9,18.8,14.6,15.8,15.8,10.1.\n",
        "```python\n",
        "create_dataset(dataset,3)\n",
        "```\n",
        "La función debiese generar $(X_1,X_2,X_3)$ e $Y$:\n",
        "\n",
        "\n",
        "|X0|X1|X2|Y|\n",
        "|---|---|---|---|\n",
        "|20.7|17.9|18.8|14.6|\n",
        "|17.9|18.8|14.6|15.8|\n",
        "|18.8|14.6|15.8|15.8|\n",
        "|14.6|15.8|15.8|10.1|\n",
        "\n",
        "\n",
        "> c) Usando la función anterior genere los conjuntos de entrenamiento y test para el problema.\n",
        "```python\n",
        "lag = 3\n",
        "trainX, trainY = create_dataset(stream_train_scaled, lag)\n",
        "testX, testY = create_dataset(stream_test_scaled, lag)\n",
        "```\n",
        "\n",
        "> d) En estos momentos tenemos nuestros datos en la forma [ejemplos, atributos]. Sin embargo, la red LSTM necesita que los datos se encuentren en un arreglo de tres dimensiones [*samples, time steps, features*]. Transforme el  train y test sets a la estructura deseada.\n",
        "```python\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "```\n",
        "\n",
        "> e) Entrene una LSTM usando un lag de 3\n",
        "```python\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_dim=lag, activation='tanh', inner_activation='sigmoid'))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=25, batch_size=1, verbose=1)\n",
        "```\n",
        "\n",
        "> f) Realice las predicciones del modelo para los conjuntos de entrenamiento y prueba. Denormalice los datos para que el error pueda ser computado en la escala original.\n",
        "```python\n",
        "trainPredict = model.predict(trainX,batch_size=batch_size)\n",
        "trainPredict = scaler.inverse_transform(trainP)\n",
        "trainY = scaler.inverse_transform([trainY])\n",
        "```\n",
        "\n",
        "> g) Compute el *root mean square error* (RMSE) sobre los conjuntos de entrenamiento y test, comente.\n",
        "```python\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# calculate root mean squared error\n",
        "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))\n",
        "```\n",
        "\n",
        "> h) Grafique las predicciones del train y test set, y contrástelas con la serie de tiempo original. Muestre un extracto de la predicción para ver en mas detalle cómo es la predicción, comente.\n",
        "```python\n",
        "# shift train predictions for plotting\n",
        "trainPredictPlot = np.empty_like(dataframe.values)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[lag:len(trainPredict)+lag, :] = trainPredict\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(dataframe.values)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[(len(trainPredict)+2*lag):, :] = testPredic\n",
        "```\n",
        "\n",
        "> i) En lugar de aumentar el número de dimensiones como el el paso e), entrene la red con un *timestep* de 3 (con dimensión de entrada 1). ¿Se produce una mejora del error de entrenamiento y pruebas? ¿Los tiempos de computación son comparables? Comente brevemente sobre cual es la forma correcta para aprovechar la información a través del tiempo, si con esta forma o la realizada en el paso e).\n",
        "```python\n",
        "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, input_dim=1, activation='tanh', inner_activation='sigmoid'))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs=25, batch_size=1, verbose=1)\n",
        "```\n",
        "\n",
        "> j) Determine el parámetro del número de bloques para la LSTM de la pregunta e) o i), lo que le parezca mas sensato en base a lo analizado en la pregunta anterior. Utilice 5-fold *cross validation*, o bien, en su defecto, los datos restante no utilizados ni como entrenamiento ni como pruebas (los de índice 2000 hacia adelante) como conjunto fijo de validación. Comente.\n",
        "```python\n",
        "nb = range(4,13,2)\n",
        "model = Sequential()\n",
        "model.add(LSTM(nb=range(4,13,2),input_dim=choose,activation='tanh',inner_activation='sigmoid'))\n",
        "model.add(Dense(1))\n",
        "```\n",
        "\n",
        "> k) Compare el desempeño de la red LSTM variando el lag de 1 a 4. Comente brevemente sobre qué resulta mejor, el tener mas información para predecir o si esto satura la predicción por el efecto del gradiente desvaneciente.\n",
        "\n",
        "> l) Usando un lag de 3, compare el desempeño de la LSTM con una red recurrente simple y una GRU. Comente sobre la convergencia y el tiempo de ejecución.\n",
        "```python\n",
        "from keras.layers import GRU\n",
        "from keras.layers import SimpleRNN\n",
        "GRU(output_dim, inner_init='orthogonal', activation='tanh')\n",
        "SimpleRNN(output_dim, inner_init='orthogonal',activation='tanh')\n",
        "```\n",
        "\n",
        "> m) Entrene la red LSTM con memoria entre batches. Grafique las predicción, comente si de esta forma mejora la predicción.\n",
        "```python\n",
        "batch_size = 1\n",
        "model = Sequential()\n",
        "model.add(LSTM(4, batch_input_shape=(batch_size, lag, 1), stateful=True))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "for i in range(25):\n",
        "    model.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)\n",
        "    model.reset_states()\n",
        "```\n",
        "> n) Compare el resultado anterior usando un tamaño de batch, decidido por usted, mayor o igual a 3.  \n",
        "> o) Construya una LSTM apilada, y compárela con la obtenida en i). Comente brevemente lo sucedido.\n",
        "```python\n",
        "model.add(LSTM(4, input_dim=1, return_sequences=True))\n",
        "model.add(LSTM(4))\n",
        "```\n",
        "\n",
        "> p) Sobre algunas de las redes definidas anteriormente deberá graficar el valor real *vs* la predicción del conjunto de pruebas tomando el primer dato (con sus $t$ *timesteps*) como inicio de la predicción y luego para predecir el siguiente valor se toman los $t-1$ *timesteps* mas el valor de predicción del primer dato, y así hasta cubrir todos los datos de pruebas. Dicho de otra forma, para los $N_t$ datos/mediciones del conjunto de pruebas, se requiere predecir los $N_t-t$ valores a partir de algun valor $p$, de la siguiente manera:\n",
        "$$\n",
        "\\hat{x}_{p} = f(x_{p-t},x_{p-t+1},\\cdots,x_{p-1}) \\\\\n",
        "\\hat{x}_{p+1} = f(x_{p+1-t},x_{p+1-t+1},\\cdots,x_{p-1},\\hat{x}_{p}) \\\\\n",
        "\\hat{x}_{p+2} = f(x_{p+2-t},x_{p+2-t+1},\\cdots,\\hat{x}_{p},\\hat{x}_{p+1}) \\\\\n",
        "\\cdots \\\\\n",
        "\\hat{x}_{N_t} = f(\\hat{x}_{N_t-t},\\hat{x}_{N_t-t+1},\\cdots,\\hat{x}_{N_t-2},\\hat{x}_{N_t-1})\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "FDBC7uFwb7t4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"segundo\"></a>\n",
        "## 2.  Redes recurrentes sobre texto\n",
        "Hoy en dı́a, una aplicación relevante de las redes neuronales recurrentes es el modelamiento de texto y lenguaje natural. En esta sección abordaremos el problema de procesar sentencias de texto proporcionadas por GMB (*Groningen Meaning Bank*) para reconocimiento de entidades y tagger. Trabajaremos con el dataset proprocionado a través de la interfaz de Kaggle en el siguiente __[link](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)__, con mas de un millón de palabras trabajaremos este dataset para realizar predicciones sobre distintas tareas, del tipo *many to many* y *many to one*.\n",
        "\n",
        "<img src=\"https://i.stack.imgur.com/b4sus.jpg\" width=\"70%\" />\n",
        "\n",
        "\n",
        "Descargue los datos de la página de Kaggle y cárgelos a través de *pandas*.\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "df_ner = pd.read_csv(\"./entity-annotated-corpus/ner.csv\", error_bad_lines=False)\n",
        "df_ner.dropna(inplace=True)\n",
        "```\n",
        "\n",
        "> a) En esta primera instancia trabajaremos con la tarea de realizar un POS *tag* (*Part of Speech*) sobre cada una de las palabras en las sentencias que se nos presenta en los datos, también puede intentar el NER (*Named Entity Recogntion*) sobre la columna *tag*, esta tarea es del tipo *many to many*, es decir, la entrada es una secuencia y la salida es una secuencia sin *shift*, por lo que necesitaremos una estructura de red adecuada a esto. En primer lugar extraiga las columnas que utilizaremos del dataset ¿Por qué es conveniente utilizar *lemma* en vez de la palabra misma *word*?\n",
        "```python\n",
        "dataset = df_ner.loc[:,[\"lemma\",\"pos\",\"tag\",\"prev-iob\"]]\n",
        "```\n",
        "Luego de esto cree una estructura que contendrá todas las sentencias u oraciones y otra estructura que contendrá los *pos tagger*, esto es un arreglo de arreglos de *lemmas* y un arreglo de arreglos de *tags* respectivamente. ¿Cuales son las dimensiones de ambas estructuras? ¿Cada dato de ejemplo tiene las mismas dimensiones que el resto?\n",
        "```python\n",
        "dataX,dataY = [],[]\n",
        "#uniques\n",
        "lemmas,labels = set(), set()\n",
        "for fila in dataset.values:\n",
        "    if fila[-1]==\"__START1__\": \n",
        "        dataX.append(np.asarray(sentence))\n",
        "        dataY.append(np.asarray(labels_sentence))\n",
        "        sentence= []\n",
        "        label_sentence = []\n",
        "    lemmas.add(fila[0])\n",
        "    labels.add(fila[1])\n",
        "    sentence.append(fila[0])#add lemma\n",
        "    labels_sentence.append(fila[1]) #POS o TAG\n",
        "#data to  array\n",
        "dataX = np.asarray(dataX[1:])\n",
        "dataY = np.asarray(dataY[1:])\n",
        "```    \n",
        "\n",
        "> b) Estudie la distribución del largo de los textos a procesar. Estudie también la frecuencia con la que aparecen\n",
        "las palabras en todo el dataset. ¿Se observa una ley Zipf? ¿Cambia el resultado cuando se separan los textos de acuerdo a su clase/categorı́a? Comente.\n",
        "\n",
        "> c) Es necesario transformar los textos para que puedan ser entregados apropiadamente a la red, por lo será necesario crear una función que codifique cada posible *lemma* a un número y cada posible *tag* a otro número, utilice esta función sobre las sentencias y *tags* ya generados. Mida cual es el largo máximo de entre todas las sentencias, la cantidad de *lemmas* y etiquetas. Además de esto, debido al largo distinto de las sentencias se deberá realizar *padding* para estandarizar el largo, considere algun carácter especial para codificar el espacio en blanco que luego se le deberá rellenar, por ejemplo si el largo máximo es de 4 y se tiene la sentencia \"the rocket\" codificada como [32,4] será necesario agregar un *lemma* que codificado significará el fin de la sentencia \"the rocket *ENDPAD ENDPAD*\" y codificado quedará como [32,4,*0, 0*].\n",
        "```python\n",
        "...#add fullfill lemma and tag to the dictionary\n",
        "lemma2idx = {w: i for i, w in enumerate(lemmas)} #Converting text to numbers\n",
        "lab2idx = {t: i for i, t in enumerate(labels)}\n",
        "dataX = [[lemma2idx[lemma] for lemma in sentence ] for sentence in dataX]\n",
        "dataY = [[lab2idx[pos] for pos in pos_tags ] for pos_tags in dataY]\n",
        "n_lemmas = len(lemmas)\n",
        "n_labels = len(labels)\n",
        "```\n",
        "\n",
        "> d) Realice el *padding* anteriormente mencionado, decida sobre qué le parece mas conveniente al rellenar con el valor especial ¿Al principio o al final de la sentencia? Comente\n",
        "```python\n",
        "from keras.preprocessing import sequence\n",
        "X = sequence.pad_sequences(dataX,maxlen=max_input_lenght,padding='post' or 'pre',value=lemma2idx[\"yourspecialcharacter\"]) \n",
        "y = sequence.pad_sequences(dataY,maxlen=max_input_lenght,padding='post' or 'pre',value=lab2idx[\"endtagger\"])\n",
        "```\n",
        "\n",
        "> e) Para el poder entregar una clasificación sobre los distintos *pos tagger* es necesario tranformarlas a *one hot vectors*, debido a que están codificadas en números enteros, con esto se quedará con un arreglo tridimensional con la cantidad de ejemplos, la cantidad máxima de palabras y la cantidad de posibles *pos tags*. Luego de esto cree los conjuntos de entrenamiento y de prueba con el código a continuación ¿Cuáles son las dimensiones de entrada y salida de cada conjunto? Comente\n",
        "```python\n",
        "from keras.utils import to_categorical\n",
        "y = np.asarray([to_categorical(i, num_classes=n_labels) for i in y])\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=22)\n",
        "```\n",
        "\n",
        "> f) Defina una red neuronal recurrente *many to many* con compuertas LSTM para aprender a *tagear* el texto, entrenela y evalúe su desempeño sobre ambos conjuntos. Esta red debe procesar la secuencia de *lemmas* rellenados (o sin rellenar) y entregar el *pos tag* a cada uno de estos *lemmas*, por lo que la salida de la red no es un vector como anteriormente se ha trabajado, sino que tiene una dimensión extra la cual es debido a que en cada instante de tiempo se necesita entregar un *output*. Como los *lemmas* corresponden a datos esencialmente categóricos, o al menos discretos, es necesario generar una representación vectorial de ellas. La primera capa de la red a construir debe por lo tanto incluir una transformación entrenable desde el espacio de representación original (discreto) a ${\\rm I\\!R}^{d}$ , con $d$ la dimensionalidad del *embedding*. Comente sobre los cambios que sufre un dato al ingresar a la red y la cantidad de parámetros de la red.\n",
        "```python\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense, Dropout\n",
        "embedding_vector = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))\n",
        "model.add(LSTM(units=100,return_sequences=True))\n",
        "model.add(Dense(n_labels, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=128)\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "```\n",
        "\n",
        "> g) Varı́e la dimensionalidad del embedding inicial y determine si aumenta o disminuye el error de clasificación. Comente.\n",
        "\n",
        "> h) Use Dropout para entrenar la LSTM. ¿El Dropout mejora el desempeño de la red? Señale cuales podrı́an ser las causas del comportamiento observado.\n",
        "```python\n",
        "from keras.layers import Dropout\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))\n",
        "model.add(LSTM(units=100,return_sequences=True)) #or recurrent_dropout=0.2\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(n_labels, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=128)\n",
        "```\n",
        "\n",
        "> i) Algunos autores señalan la importante dependencia que existe en texto, no solo con las palabras anteriores, sino que con las que siguen. Mejore la red definida en f) utilizando una red neuronal recurrente Bidireccional, es decir, con recurrencia en ambas direcciones sobre la secuencia de *lemmas* de entrada. Comente cuál debiera ser la forma correcta de usar el parámetro *merge_mode* (concatenar, multiplicar, sumar o promediar) para este caso. Además comente las transformaciones que sufre el patrón de entrada al pasar por las capas. ¿Mejora o empeora el desempeño? Analice.\n",
        "```python\n",
        "from keras.layers import Bidirectional\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=n_lemmas, output_dim=embedding_vector, input_length=max_input_lenght))\n",
        "layer_lstm = LSTM(units=100,return_sequences=True)\n",
        "model.add(Bidirectional(layer_lstm,merge_mode=choose))\n",
        "model.add(Dense(n_labels, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=3, batch_size=128)\n",
        "```\n",
        "\n",
        "> j) Utilice alguna de las red entrenadas, ojalá una con buen desempeño y muestre las predicciones, el *pos tager*, sobre algún ejemplo de pruebas, comente. Para entender qué son los símbolos *Part of speech tags* visite el siguiente link: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html \n",
        "```python\n",
        "p = model.predict(np.array([X_test[i]]))\n",
        "p = np.argmax(p, axis=-1)\n",
        "print(\"{:15}: {}\".format(\"Lemma\", \"Pred\"))\n",
        "for w,pred in zip(X_test[i],p[0]):\n",
        "    print(\"{:15}: {}\".format(lemmas[w],labels[pred]))\n",
        "```\n",
        "\n",
        "Ahora utilizaremos el mismo dataset para realizar una aplicación mas conocida hoy en día que es el autocompletar texto, esto es, predecir la siguiente palabra de una sentencia basada en las palabras anteriores de la misma, por lo que la red que utilizaremos es del tipo *many to one*.  \n",
        "Debido a lo extenso del vocabulario es bastante complejo hacer un modelo que prediga una palabra dentro de las millones que pueden haber, por lo que, trabajaremos a nivel de carácter, en donde las posibilidades (posibles clases) son mucho menores.\n",
        "\n",
        "> k) Carge las palabras del dataset ¿Por qué no los *lemmas*? y cree el corpus con el cual se trabajará, además de crear la codificación de caracteres a números. Esto se presenta en el código a continuación además de crear la estrucutura de los datos con los que se va a trabajar (sub sentencias del corpus original). Utilice el tamaño del *corpus* que le acomode a la memoria de su computador.\n",
        "```python\n",
        "dataset = df_ner.loc[:,[\"word\",\"lemma\"]]\n",
        "text = ' '.join(dataset[\"word\"]).lower() #corpus\n",
        "null_character = \"*\"\n",
        "chars = [null_character]+sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = {c: i for i, c in enumerate(chars)}\n",
        "indices_char = {i: c for i, c in enumerate(chars)}\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 5 \n",
        "sentences = []\n",
        "next_chars = []\n",
        "size = int(len(text)*0.2) #solo un 20% del corpus\n",
        "for i in range(0, size - maxlen, step):\n",
        "    sentences.append(null_character+text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "```\n",
        "\n",
        "> l) Procese las sentencias para así tenerlas codificadas en números que van a representar los carácteres, tal cual se realizó en c) con los *lemmas*, lo mismo para las etiquetas. Además de esto deberá realizar el *padding* correspondiente al comienzo de la sentencia, esto es para que la red aprenda cuando venga una frase mas corta de lo entrenado, este símbolo siignificará que no hay información. Transforme las etiquetas a *one hot vector* como se realizó en c) y defina la red similar a la presentada en f), con un *embedding* seguido de una capa recurrente GRU y la capa de clasificación. Aprovechese de la implementación más rápida de GRU respaldada por __[CuDNN](https://developer.nvidia.com/cudnn)__, una librería de CUDA (NVIDIA) para *Deep Neural Network*. \n",
        "```python\n",
        "dataX = [[char_indices[char] for char in sentence ] for sentence in sentences]\n",
        "dataY = [char_indices[char] for char in next_chars]\n",
        "...#dataX pad sequence padding='pre'\n",
        "...#dataY to categorical with num_classes=len(chars)\n",
        "from keras.layers import CuDNNGRU,GRU\n",
        "embedding_vector = 16\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(chars), output_dim=embedding_vector, input_length=maxlen+1))#\n",
        "model.add(CuDNNGRU(units=512,return_sequences=False)) #or GRU\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "```\n",
        "\n",
        ">  m) Entrene la red con las funciones que se presentan a continuación que mostrarán el cómo va la tarea de autocompletar texto en cada *epoch*, generando una sentencia completa de 400 carácteres *aleatoriamente* a partir de una semilla *random*. Entrene solo durante 25 *epochs*, a los 15 ya debería comenzar a generar palabras y sonar mas coherente.\n",
        "```python\n",
        "def predict_next_char(model, sentence, diversity=1.0):\n",
        "    \"\"\"Predict the next character from the current one\"\"\"    \n",
        "    x_pred = [char_indices[null_character]]+[char_indices[char] for char in sentence]\n",
        "    x_pred = sequence.pad_sequences([x_pred], maxlen=maxlen+1,padding='pre',value=char_indices[null_character])\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = np.random.choice(len(chars), p=preds)\n",
        "    return indices_char[next_index]\n",
        "import random,sys\n",
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print('\\n----- Generating text after Epoch: %d' % epoch)\n",
        "    start_index = random.randint(0, size - maxlen - 1)\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(sentence)\n",
        "    for i in range(400):\n",
        "        next_char = predict_next_char(model, sentence0)\n",
        "        sentence = sentence[1:] + next_char #for next character\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    return\n",
        "from keras.callbacks import LambdaCallback\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "model.fit(X, y,batch_size=256,epochs=25, callbacks=[print_callback])\n",
        "```\n",
        "\n",
        "> n) Verifique la calidad de la red entrenada, cargando el modelo si es que lo guardó o directamente, entregando una predicción sobre una semilla inicial que usted entregue. Observe y comente cualitativamente sobre qué pasa cuando la predicción del siguiente carácter fuese de manera determinista, tomando el máximo valor de entre las predicciones.\n",
        "```python\n",
        "sentence = \"it is \"\n",
        "print('----- Generating with seed: \"' + sentence + '\"')\n",
        "sys.stdout.write(sentence)\n",
        "for i in range(400):\n",
        "    next_char = predict_next_char(model, sentence)\n",
        "    sentence = sentence[1:] + next_char \n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "PVdtX850b7t4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"tercero\"></a>\n",
        "## 3. Autoencoders (AEs) en MNIST\n",
        "Como se ha discutido en clases, las RBM’s y posteriormente los AE’s (redes no supervisadas) fueron un componente crucial en el desarrollo de los modelos que entre 2006 y 2010 vigorizaron el área de las redes neuronales artificiales con logros notables de desempeño en diferentes tareas de aprendizaje automático. En esta sección aprenderemos a utilizar el más sencillo de estos modelos: un autoencoder o AE. Consideraremos tres aplicaciones clásicas: reducción de dimensionalidad, denoising y pre-entrenamiento. Con este objetivo en mente, utilizaremos un dataset denominado MNIST. Se trata de una colección de 70000 imágenes de 28 $\\times$ 28 pixeles correspondientes a dígitos manuscritos (números entre 0 y 9). En su versión tradicional, la colección se encuentra separada en dos subconjuntos: uno de entrenamiento de 60000 imágenes y otro de test de 10000 imágenes. La tarea consiste en construir un programa para que aprenda a identificar correctamente el dı́gito representado en la imagen\n",
        "\n",
        "\n",
        "> a) Escriba una función que cargue los datos desde el repositorio de keras, normalice las imágenes de modo que los pixeles queden en [0, 1], transforme las imágenes en vectores ($\\in {\\rm I\\!R}^{784}$) y devuelva tres subconjuntos disjuntos: uno de entrenamiento, uno de validación y uno de pruebas. Construya el conjunto de validación utilizando los últimos $nval = 5000$ casos del conjunto del entrenamiento. El conjunto de entrenamiento consistirá en las primeras $60000 - nval$ imágenes.\n",
        "```python\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255. #and x_test\n",
        "#Define here your validation set\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "```\n",
        "\n",
        "### 3.1 Reducción de dimensionalidad\n",
        "Para esta primera sección se trabajará con un autoencoder tradicional (*feed forward*) en donde las capas de este son densas. Para esto se re estructuraran los datos de entradas en forma de vector, es decir la matriz de 28 $\\times$ 28 pasa a ser un vector de 784 componentes.\n",
        "\n",
        "```python\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "```\n",
        "\n",
        "Una de las aplicaciones tı́picas de un AE es reducción de dimensionalidad, es decir, implementar una transformación $\\phi:{\\rm I\\!R}^d \\leftarrow {\\rm I\\!R}^{d'}$ de objetos representados originalmente por $d$ atributos en una nueva representación de $d'$ atributos, de modo tal que se preserve lo mejor posible la “información” original. Obtener tal representación es útil desde un punto de vista computacional (compresión) y estadı́stico (permite construir modelos con un menor número de parámetros libres). Un AE es una técnica de reducción de dimensionalidad no supervisada porque no hace uso de información acerca de las clases a las que pertenecen los datos de entrenamiento\n",
        "> a) Entrene un AE básico (1 capa escondida) para generar una representación de MNIST en $d'$= 2, 8, 32, 64 dimensiones. Justifique la elección de la función de pérdida a utilizar y del criterio de entrenamiento en general. Determine el porcentaje de compresión obtenido y el error de reconstrucción en cada caso. ¿Mejora el resultado si elegimos una función de activación **ReLU** para el Encoder? ¿Podrı́a utilizarse esta activación en el Decoder?\n",
        "```python\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(32, activation='sigmoid')(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "autoencoder = Model(input=input_img, output=decoded)\n",
        "encoder = Model(input=input_img, output=encoded)\n",
        "encoded_input = Input(shape=(32,))\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = Model(input=encoded_input, output=decoder_layer(encoded_input))\n",
        "##\n",
        "autoencoder.compile(optimizer=SGD(lr=1.0), loss='binary_crossentropy')\n",
        "autoencoder.fit(x_train,x_train,epochs=50,batch_size=32,validation_data=(x_val,x_val))\n",
        "autoencoder.save('basic_autoencoder_768x32.h5')\n",
        "#save other stuffs\n",
        "```\n",
        "\n",
        "> b) Compare visualmente la reconstrucción que logra hacer el autoencoder desde la representación en ${\\rm I\\!R}^{d'}$ para algunas imágenes del conjunto de pruebas. Determine si la percepción visual se corresponde con el error de reconstrucción observada. Comente.\n",
        "```python\n",
        "from keras.models import load_model\n",
        "autoencoder = load_model('basic_autoencoder_768x32.h5')\n",
        "#load other stuff ...\n",
        "encoded_test = encoder.predict(x_test)\n",
        "decoded_test = decoder.predict(encoded_test)\n",
        "import matplotlib\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28),cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_test[i].reshape(28, 28),cmap='gray')\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "> c) Para verificar la calidad de la representación obtenida, implemente el clasificador denominado $kNN$ (k-nearest neighbor): dada una imagen $x$, el clasificador busca las k = 10 imágenes de entrenamiento más similares (de acuerdo a una distancia, e.g. euclidiana) y predice como clase, la etiqueta más popular entre las imágenes cercanas. Mida el error de pruebas obtenido construyendo este clasificador sobre la data reducida a través del autocnder comparando con la representación reducida obtenida vía PCA (una técnica clásica de reducción de dimensionalidad) utilizando el mismo número de dimensiones $d'$= 2, 4, 8, 16, 32. Considere tanto el error de reconstrucción como el desempeño en clasificación , además de comparar los tiempos medios de predicción en ambos escenarios.\n",
        "```python\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "pca = PCA(n_components=d)\n",
        "#PCA\n",
        "pca.fit(x_train)\n",
        "pca_train = pca.transform(x_train)\n",
        "pca_test = pca.transform(x_test)\n",
        "#AUTOENCODER\n",
        "encoded_train = encoder.predict(x_train)\n",
        "encoded_test = encoder.predict(x_test)\n",
        "#CLASIFICATION\n",
        "clf = KNeighborsClassifier(10)\n",
        "clf.fit(pca_train, y_train)\n",
        "print 'Classification Accuracy PCA %.2f' % clf.score(pca_test,y_test)\n",
        "clf = KNeighborsClassifier(10)\n",
        "clf.fit(encoded_train, y_train)\n",
        "print 'Classification Accuracy %.2f' % clf.score(encoded_test,y_test)\n",
        "```\n",
        "\n",
        "> d) Modifique el autoencoder básico construido en (a) para implementar un deep autoencoder (*deep AE*), es decir, un autoencoder con al menos dos capas ocultas. Demuestre experimentalmente que este autoencoder puede mejorar la compresión obtenida por PCA utilizando el mismo número de dimensiones $d'$ . Experimente con $d'$ =2, 4, 8, 16 y distintas profundidades (L = 2, 3, 4). Considere en esta comparación tanto el error de reconstrucción como el desempeño en clasificación (vı́a kNN) de cada representación. Comente.\n",
        "```python\n",
        "target_dim = 2 #try other and do a nice plot\n",
        "input_img = Input(shape=(784,))\n",
        "encoded1 = Dense(1000, activation='relu')(input_img)\n",
        "encoded2 = Dense(500, activation='relu')(encoded1)\n",
        "encoded3 = Dense(250, activation='relu')(encoded2)\n",
        "encoded4 = Dense(target_dim, activation='relu')(encoded3)\n",
        "decoded4 = Dense(250, activation='relu')(encoded4)\n",
        "decoded3 = Dense(500, activation='relu')(encoded3)\n",
        "decoded2 = Dense(1000, activation='relu')(decoded3)\n",
        "decoded1 = Dense(784, activation='sigmoid')(decoded2)\n",
        "autoencoder = Model(input=input_img, output=decoded1)\n",
        "encoder = Model(input=input_img, output=encoded3)\n",
        "autoencoder.compile(optimizer=SGD(lr=1.0), loss='binary_crossentropy')\n",
        "autoencoder.fit(x_train,x_train,epochs=40,batch_size=32,validation_data=(x_val,x_val))\n",
        "autoencoder.save('my_autoencoder_768x1000x500x250x2.h5')\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "pca = PCA(n_components=target_dim)\n",
        "pca.fit(x_train)\n",
        "```\n",
        "\n",
        "> e) Elija algunas de las representaciones aprendidas anteriormente y visualı́celas usando la herramienta *TSNE* disponible en la librerı́a *sklearn*. Compare cualitativamente el resultado con aquel obtenido usando PCA con el mismo número de componentes\n",
        "```python\n",
        "nplot=5000 #warning: mind your memory!\n",
        "encoded_train = encoder.predict(x_train[:nplot])\n",
        "from sklearn.manifold import TSNE\n",
        "model = TSNE(n_components=2, random_state=0)\n",
        "encoded_train = model.fit_transform(encoded_train)\n",
        "plt.figure(figsize=(10, 10))\n",
        "colors={0:'b',1:'g',2:'r',3:'c',4:'m',5:'y',6:'k',7:'orange',8:'darkgreen',9:'maroon'}\n",
        "markers={0:'o',1:'+',2: 'v',3:'<',4:'>',5:'^',6:'s',7:'p',8:'*',9:'x'}\n",
        "for idx in xrange(0,nplot):\n",
        "    label = y_train[idx]\n",
        "    line = plt.plot(encoded_train[idx][0], encoded_train[idx][1],\n",
        "        color=colors[label], marker=markers[label], markersize=6)\n",
        "pca_train = pca.transform(x_train)\n",
        "encoded_train = pca_train[:nplot]\n",
        "... #plot PCA\n",
        "```\n",
        "\n",
        "> f) Modifique el autoencoder construido en (a) para trabajar directamente sobre las imágenes de MNIST, sin tratarlas como vectores de 784 atributos, sino como matrices de tamaño $1\\times28\\times28$. Es posible lograr este objetivo utilizando capas convolucionales para definir el Encoder y el Decoder, comente como sufre las transformaciones el patrón de entrada. Compare la calidad de la representación reducida obtenida por el nuevo autoencoder con aquella obtenida anteriormente utilizando el mismo número de dimensiones. Comente.\n",
        "```python\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) #modify for th dim ordering\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "input_img = Input(shape=(28, 28, 1))\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), border_mode='same')(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "autoencoder.summary()\n",
        "```\n",
        "\n",
        "### 3.2 Denoising\n",
        "Como se ha discutido en clases, un denoising autoencoder (dAE) es esencialmente un autoencoder entrenado para reconstruir ejemplos parcialmente corruptos. Varios autores han demostrado que mediante esta modificación simple es posible obtener representaciones más robustas y significativas que aquellas obtenidas por un AE básico. En esta sección exploraremos la aplicación más “natural” o “directa” del método.\n",
        "\n",
        "> a) Genere artificialmente una versión corrupta de las imágenes en MNIST utilizando el siguiente modelo de ruido (masking noise): si $x\\in {\\rm I\\!R}^d$ es una de las imágenes originales, la versión ruidosa $\\~{x}$ se obtiene como $\\~{x} = x \\odot \\xi$ donde $\\odot$ denota el producto de Hadamard (componente a componente) y $\\xi \\in {\\rm I\\!R}^d$ es un vector aleatorio binario con componentes *Ber(p)* independientes.\n",
        "```python\n",
        "from numpy.random import binomial\n",
        "noise_level = 0.1\n",
        "noise_mask = binomial(n=1,p=noise_level,size=x_train.shape)\n",
        "noisy_x_train = x_train*noise_mask\n",
        "noise_mask = binomial(n=1,p=noise_level,size=x_val.shape)\n",
        "noisy_x_val = x_val*noise_mask\n",
        "noise_mask = binomial(n=1,p=noise_level,size=x_test.shape)\n",
        "noisy_x_test = x_test*noise_mask\n",
        "```\n",
        "\n",
        "> b) Entrene un autoencoder para reconstruir las imágenes corruptas generadas en el ı́tem anterior. Mida el error de reconstrucción y evalúe cualitativamente (visualización de la imagen corrupta y reconstruida) el resultado para un subconjunto representativo de imágenes. Experimente diferentes valores de *p* en el rango (0, 1).\n",
        "```python\n",
        "# DEFINE YOUR AUTOENCODER AS BEFORE\n",
        "autoencoder.fit(noisy_x_train, x_train, epochs=40, batch_size=32, validation_data=(noisy_x_val, x_val))\n",
        "```\n",
        "\n",
        "> c) Utilice estas imágenes intencionalmente corruptas para entrenar un AE con fines de reducción de dimensionalidad. Durante el entrenamiento, proceda exactamente como en (b), pero su objetivo no será hacer *denoising* sino obtener una representación comprimida de alta calidad de las imágenes originales. Al final del entrenamiento, mida el error de reconstrucción como el desempeño en clasificación (vı́a kNN como en la sección anterior) de la representación obtenida. Comente.\n",
        "\n",
        "> d) Diseñe otra manera de generar imágenes corruptas del dataset MNIST, por ejemplo algún tipo de ruido, sea creativo. Mida el error de reconstrucción y evalúe cualitativamente (visualización de la imagen corrupta y reconstruida) el resultado para un subconjunto representativo de imágenes"
      ]
    },
    {
      "metadata": {
        "id": "YDgW2sa3b7t5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"cuarto\"></a>\n",
        "## 4. Transfer Learning\n",
        "En esta sección se trabajará con el dataset trabajado anteriormente, CIFAR [3], pero en su versión mas fina en el cual se presentan 100 tipos distintos de categorías a clasificar la imagen, no 10 como se usó en las actividades anteriores. La estructura es la misma, son 60000 imágenes RGB de 32 $\\times$ 32 píxeles separados en 50 mil de entrenamiento y 10 mil de pruebas.  \n",
        "Aquí se experimentará con el concepto de *transfer learning* el cual consta en transferir conocimiento de un dominio fuente (*source domain*) a un dominio objetivo (*target domain*). En redes neuronales existen muchas representaciones de esto, en común consta en pre inicializar los pesos de la red de alguna manera que no sea con distribuciones de manera aleatoria. También está lo que es utilizar una representación generada a través de otra red entrenada con muchos datos, esto es tomar la red y \"*congelar*\" sus primeras capas para tomar esta representación y no entrenar esos pesos.  \n",
        "\n",
        "Para cargar los datos utilice el siguiente comando:\n",
        "```python\n",
        "from keras.datasets import cifar100\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "```\n",
        "\n",
        "Normalice y transforme las etiquetas en *one hot* vector.\n",
        "```python\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=100)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=100)\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "```\n",
        "\n",
        "> a) Entrene una red neuronal convolucional como se presenta en el código a continuación durante 15 *epochs*, realizando un gráfico de evolución de la función de pérdida y de la exactitud del algoritmo (*accuracy*) sobre ambos conjuntos, entrenamiento y pruebas. Comente sobre el tiempo de ejecución de este entrenamiento. Reporte el *accuracy* del modelo final sobre el conjunto de pruebas.\n",
        "```python\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:],activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3),padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "...#add clasification layer\n",
        "model.summary()\n",
        "```\n",
        "<div class=\"alert alert-block alert-info\">Se utiliza una tasa de aprendizaje pequeña ya que es lo recomendable en *transfer learning*.</div>\n",
        "```python\n",
        "#train it\n",
        "optimizer_ = SGD(lr=0.01,momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=128,epochs=15,verbose=1, validation_data=(x_test,y_test))\n",
        "```\n",
        "\n",
        "> b) Debido al comportamiento de las curvas de entrenamiento, claramente se ve que se necesita un regularizador. Experimente utilizando Dropout con una tasa de 0.25 en las tandas convolucionales, elija donde situarlo, luego de la primera convolución, después de la segunda, solamente después del *pooling*, en todas o alguna forma que le parezca conveniente, de argumentos de ello. La idea es que se forme una idea de dónde conviene colocar el regularizador y porqué.\n",
        "\n",
        "> c) Como pre entrenamiento de la misma red definida en a) de una manera no supervisada se trabajará con un autoencoder convolucional, el cual no necesita etiqueta de los datos por lo que se puede aprovechar de transferir lo aprendido con datos sin conocer si pertenecen a la misma categoría o no. Comente y analice si esto mejora lo visto en a). *Utilice todas las imágenes no etiquetadas que desee*.\n",
        "```python\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "###BUILD AUTOENCODER1\n",
        "input_img = Input(shape=x_train.shape[1:])\n",
        "encoded1 = Conv2D(hidden_layer1, (3, 3),activation=activation_1,padding='same')(input_img)\n",
        "decoded1 = Conv2D(3, (3, 3), activation=decoder_activation, padding='same')(encoded1)\n",
        "autoencoder1 = Model(input_img, decoded1)\n",
        "autoencoder1.compile(optimizer='adam', loss=loss_)\n",
        "autoencoder1.summary()\n",
        "autoencoder1.fit(x_train, x_train, epochs=15, batch_size=128,validation_data=(x_test, x_test))\n",
        "autoencoder1.save('autoencoder_layer1.h5')\n",
        "###BUILD AUTOENCODER2\n",
        "encoded1 = autoencoder1.layers[1](autoencoder1.input)\n",
        "#AUTOENCODER2\n",
        "encoded2 = Conv2D(hidden_layer2,(3, 3), activation=activation_2, padding='same')(encoded1) \n",
        "decoded2 = Conv2D(hidden_layer1,(3, 3), activation=decoder_activation2,padding='same')(encoded2) \n",
        "#finish AUTOENCODER2\n",
        "decoded1 = autoencoder1.layers[-1](decoded2)\n",
        "autoencoder2 = Model(autoencoder1.input, decoded1) #all model\n",
        "#autoencoder1 set fixed\n",
        "autoencoder2.layers[1].trainable=False\n",
        "autoencoder2.layers[-1].trainable=False\n",
        "autoencoder2.compile(optimizer='adam', loss=loss_)\n",
        "autoencoder2.summary()\n",
        "autoencoder2.fit(x_train, x_train, epochs=10, batch_size=128,validation_data=(x_test, x_test))\n",
        "autoencoder2.save('autoencoder_layer2.h5')\n",
        "#FINE TUNNING\n",
        "model = Sequential()\n",
        "model.add(Conv2D(hidden_layer1,(3, 3),padding='same',activation=activation_1,input_shape=x_train.shape[1:]))\n",
        "model.layers[-1].set_weights(autoencoder1.layers[1].get_weights())\n",
        "model.add(Conv2D(hidden_layer2, (3, 3),padding='same',activation=activation_2))\n",
        "model.layers[-1].set_weights(autoencoder2.layers[2].get_weights())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "...#rest of the model\n",
        "optimizer_ = keras.optimizers.SGD(lr=0.01,momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=128,epochs=15,verbose=1, alidation_data=(x_test, y_test))\n",
        "```\n",
        "\n",
        "> d) Otra forma de hacer lo que se conoce como *transfer learning* es utilizar el conocimiento (los parámetros) aprendido por una red entrenada con millones de imágenes, y tomar estos parámetros como los pre entrenados. Para esto se utilizará el modelo VGG16 [7] proporcionado a través de la interfaz de keras. Visualice el modelo y sus 23 capas. Para esta instancia se utilizará todo lo aprendido por las capas convolucionales, es decir, se eliminan las capas densas del modelo y se agregan unas nuevas a ser entrenadas desde cero.\n",
        "```python\n",
        "from keras.applications import VGG16\n",
        "#LOAD PRETRAINED MODEL \n",
        "input_tensor=Input(shape=x_train.shape[1:])\n",
        "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor )\n",
        "features_train = modelVGG.predict(x_train)\n",
        "features_test = modelVGG.predict(x_test)\n",
        "modelVGG.summary()\n",
        "```\n",
        "\n",
        "> e) Entrene esta red agregando una capa densa de 1024 neuronas seguido de un dropout de 0.5, finalmente es necesario agregar la capa de clasificación para las 100 clases. Utilice la misma configuración del optimizador para que las comparaciones sean válidas. Entrene unicamente por 10 *epochs* ¿Qué sucede? Comente.\n",
        "```python\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "...#clasification\n",
        "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(features_train, y_train,epochs=epochs_, batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
        "```\n",
        "\n",
        "> f) Agregue una capa de normalización (*Batch Normalization* [8]) de las activaciones en las capas densas, esto es, restar por la media del batch y dividir por la desviación estándar. Vuelva a entrenar el modelo con la misma configuración pero ahora por **15 *epochs***. Comente lo observado y compare las curvas de convergencia con los modelos anteriores ¿Por qué esto mejora a lo presentado en e)? Realice los mismos gráficos que en a) a través del número de *epochs* y comente sobre el tiempo de ejecución de este entrenamiento.\n",
        "```python\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "...\n",
        "```\n",
        "\n",
        "> g) Anteriormente se dejaron fijas las capas de convolución de VGG16, ahora experimente comentando sobre la convergencia y el tiempo de ejecución el entrenar la última tanda de convoluciones de VGG16, es decir, tome como punto inicial los pesos pre entrenados de esta red en *Imagenet* y entrenelos para este problema.\n",
        "```python\n",
        "#LOAD PRETRAINED MODEL \n",
        "input_tensor=Input(shape=x_train.shape[1:])\n",
        "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor )\n",
        "salida_vgg = modelVGG.get_layer('block4_pool').output_shape\n",
        "model = Sequential()\n",
        "model.add(Conv2D(512,(3, 3),input_shape=salida_vgg[1:],activation='relu',padding='same'))\n",
        "model.add(Conv2D(512,(3, 3),activation='relu',padding='same'))\n",
        "model.add(Conv2D(512,(3, 3),activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D((2, 2),strides=(2,2)))    \n",
        "##dense section\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "#delete last 4 layers of VGG16 and transfer the weight to new model\n",
        "modelVGG.layers.pop() #delete last maxpooling\n",
        "for i in np.arange(2,-1,-1):\n",
        "    last = modelVGG.layers.pop() #delete convolutional layers\n",
        "    model.layers[i].set_weights(last.get_weights())\n",
        "from keras.models import Model\n",
        "crop_modelVGG = Model(inputs=modelVGG.input, outputs=modelVGG.layers[-1].output)\n",
        "features_train = crop_modelVGG.predict(x_train)\n",
        "features_test = crop_modelVGG.predict(x_test)\n",
        "#train it\n",
        "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(features_train,y_train,epochs=15,batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Ij_U5gU5b7t5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<a id=\"refs\"></a>\n",
        "## Referencias\n",
        "[1] Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P. A. *Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion*. Journal of Machine Learning Research 11. pp 3371–3408, 2010.  \n",
        "[3]  Bishop, Christopher M. (1995), *Neural Networks for Pattern Recognition,* Clarendon Press.  \n",
        "[4] Krizhevsky, A., Hinton, G. (2009). *Learning multiple layers of features from tiny images*.  \n",
        "[5] *Scikit-learn: Machine Learning in Python.* http://scikit-learn.org/stable/  \n",
        "[6] Holden, D., Saito, J., Komura, T., & Joyce, T. (2015, November). *Learning motion manifolds with convolutional autoencoders.* In SIGGRAPH Asia 2015 Technical Briefs (p. 18). ACM.  \n",
        "[7] Simonyan, K., & Zisserman, A. (2014). *Very deep convolutional networks for large-scale image recognition.* arXiv preprint arXiv:1409.1556.  \n",
        "[8] Ioffe, S., & Szegedy, C. (2015). Batch normalization: *Accelerating deep network training by reducing internal covariate shift*. arXiv preprint arXiv:1502.03167.  \n",
        "[9] Schuster, M., & Paliwal, K. K. (1997). *Bidirectional recurrent neural networks.* IEEE Transactions on Signal Processing, 45(11), 2673-2681.  \n",
        "[10] LeCun, Y., Bengio, Y., & Hinton, G. (2015). *Deep learning*. nature, 521(7553), 436.  \n",
        "[11] https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
      ]
    }
  ]
}